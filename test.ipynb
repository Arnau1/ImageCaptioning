{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq, BitsAndBytesConfig\n",
    "from transformers.image_utils import load_image\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Specify device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define paths directly\n",
    "images_path = \"/path/to/images\" \n",
    "pickle_path = \"/path/to/test_titles.pkl\"  \n",
    "\n",
    "class Inference:\n",
    "    def __init__(self, images_path, pickle_path):\n",
    "        self.images_path = images_path\n",
    "        self.pickle_path = pickle_path\n",
    "        # Load the pickle file\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            # A dictionary with keys 'image_name' and 'title'\n",
    "            self.titles = pickle.load(f)\n",
    "\n",
    "        self.processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Base\")\n",
    "        quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        self.model = AutoModelForVision2Seq.from_pretrained(\n",
    "            \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "            quantization_config=quantization_config,\n",
    "        )\n",
    "        self.model.to(DEVICE)\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        image = load_image(image_path)\n",
    "        return image\n",
    "\n",
    "    def generate_description(self, image_path):\n",
    "        image = self.load_image(image_path)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": \"Can you describe the image?\"}\n",
    "                ]\n",
    "            },\n",
    "        ]\n",
    "        prompt = self.processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "        inputs = self.processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        generated_ids = self.model.generate(**inputs, max_new_tokens=50)\n",
    "        generated_texts = self.processor.batch_decode(\n",
    "            generated_ids,\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        return (generated_texts[0], os.path.basename(image_path))\n",
    "    \n",
    "    def save_to_json(self, descriptions, output_file='descriptions.json'):\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(descriptions, f)\n",
    "\n",
    "    def process_images(self, output_file='descriptions.json'):\n",
    "        descriptions = []\n",
    "        image_names = os.listdir(self.images_path)\n",
    "        image_names = [image_name for image_name in image_names if os.path.basename(image_name) in self.titles]\n",
    "\n",
    "        progress_bar = tqdm(image_names, desc=\"Processing Images\", unit=\"image\")\n",
    "        for image_name in progress_bar:\n",
    "            image_path = os.path.join(self.images_path, image_name)\n",
    "            if os.path.isfile(image_path):\n",
    "                description = self.generate_description(image_path)\n",
    "                descriptions.append(description)\n",
    "        self.save_to_json(descriptions, output_file)\n",
    "\n",
    "# Instantiate the class\n",
    "inference = Inference(images_path, pickle_path)\n",
    "\n",
    "# Process the images and save descriptions\n",
    "output_file = \"descriptions.json\"  # Define output file\n",
    "inference.process_images(output_file)\n",
    "\n",
    "# Load and view saved descriptions\n",
    "with open(output_file, 'r') as f:\n",
    "    descriptions = json.load(f)\n",
    "\n",
    "# Display some results\n",
    "print(descriptions[:5])  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
